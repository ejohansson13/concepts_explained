{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNI4Pfnpogh6mvrKQEnaiYX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Import libraries"],"metadata":{"id":"MDCb1aQmFPqR"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"-XcwUl6yFO1t","executionInfo":{"status":"ok","timestamp":1715119393925,"user_tz":420,"elapsed":8452,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Operations block"],"metadata":{"id":"r77wpzMuDqqa"}},{"cell_type":"code","source":["def conv_block(in_channels, out_channels):\n","  conv_ops = nn.Sequential(\n","      nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n","      nn.BatchNorm2d(out_channels),\n","      nn.ReLU(inplace=True),\n","      nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n","      nn.BatchNorm2d(out_channels),\n","      nn.ReLU(inplace=True),\n","  )\n","\n","  return conv_ops"],"metadata":{"id":"RA-BqpH_DoFi","executionInfo":{"status":"ok","timestamp":1715119394176,"user_tz":420,"elapsed":253,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["U-Net Class\n","\n"],"metadata":{"id":"3quONue8D57N"}},{"cell_type":"code","source":["class UNet(nn.Module):\n","  def __init__(self, in_channels, num_classes):\n","    super(UNet, self).__init__()\n","\n","    # assign number of channels for input image\n","    self.in_channels = in_channels\n","\n","    # assign number of classes for output layer\n","    self.num_classes = num_classes\n","\n","    # declare max pooling operation\n","    self.max_pool = nn.MaxPool2d(2, 2)\n","\n","    # declare all downward blocks of convolution+activation\n","    self.down_conv1 = conv_block(in_channels=self.in_channels, out_channels=64)\n","    self.down_conv2 = conv_block(in_channels=64, out_channels=128)\n","    self.down_conv3 = conv_block(in_channels=128, out_channels=256)\n","    self.down_conv4 = conv_block(in_channels=256, out_channels=512)\n","\n","    # declare bridge convolution block\n","    self.bridge = conv_block(in_channels=512, out_channels=1024)\n","\n","    # declare up-sampling transformations\n","    self.conv_trans1 = nn.ConvTranspose2d(\n","        in_channels=1024,\n","        out_channels=512,\n","        kernel_size=2,\n","        stride=2,\n","    )\n","    self.conv_trans2 = nn.ConvTranspose2d(\n","        in_channels=512,\n","        out_channels=256,\n","        kernel_size=2,\n","        stride=2,\n","    )\n","    self.conv_trans3 = nn.ConvTranspose2d(\n","        in_channels=256,\n","        out_channels=128,\n","        kernel_size=2,\n","        stride=2,\n","    )\n","    self.conv_trans4 = nn.ConvTranspose2d(\n","        in_channels=128,\n","        out_channels=64,\n","        kernel_size=2,\n","        stride=2,\n","    )\n","\n","    # declare upward convolution+activation blocks\n","    self.up_conv1 = conv_block(in_channels=1024, out_channels=512)\n","    self.up_conv2 = conv_block(in_channels=512, out_channels=256)\n","    self.up_conv3 = conv_block(in_channels=256, out_channels=128)\n","    self.up_conv4 = conv_block(in_channels=128, out_channels=64)\n","\n","    # declare final layer\n","    self.final = nn.Conv2d(\n","        in_channels=64,\n","        out_channels=self.num_classes,\n","        kernel_size=1\n","    )\n","\n","  def forward(self, x):\n","    skip_connections = []\n","\n","    # encoding path: convolve, downsample\n","    x1 = self.down_conv1(x)\n","    skip_connections.append(x1)\n","    x1_pool = self.max_pool(x1)\n","\n","    x2 = self.down_conv2(x1_pool)\n","    skip_connections.append(x2)\n","    x2_pool = self.max_pool(x2)\n","\n","    x3 = self.down_conv3(x2_pool)\n","    skip_connections.append(x3)\n","    x3_pool = self.max_pool(x3)\n","\n","    x4 = self.down_conv4(x3_pool)\n","    skip_connections.append(x4)\n","    x4_pool = self.max_pool(x4)\n","\n","    # bridge\n","    x_5 = self.bridge(x4_pool)\n","\n","    # decoding path: upsample, concatenate, convolve\n","    x6_up = self.conv_trans1(x_5)\n","    x6_cat = torch.cat((skip_connections.pop(), x6_up), dim=1)\n","    x6 = self.up_conv1(x6_cat)\n","\n","    x7_up = self.conv_trans2(x6)\n","    x7_cat = torch.cat((skip_connections.pop(), x7_up), dim=1)\n","    x7 = self.up_conv2(x7_cat)\n","\n","    x8_up = self.conv_trans3(x7)\n","    x8_cat = torch.cat((skip_connections.pop(), x8_up), dim=1)\n","    x8 = self.up_conv3(x8_cat)\n","\n","    x9_up = self.conv_trans4(x8)\n","    x9_cat = torch.cat((skip_connections.pop(), x9_up), dim=1)\n","    x9 = self.up_conv4(x9_cat)\n","\n","    x_final = self.final(x9)\n","\n","    return x_final"],"metadata":{"id":"O6bAIe8aDy3_","executionInfo":{"status":"ok","timestamp":1715119394176,"user_tz":420,"elapsed":2,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Dimensions check"],"metadata":{"id":"yb7KP2pApQKL"}},{"cell_type":"code","source":["if __name__ == '__main__':\n","    input_image = torch.rand((1, 3, 512, 512))\n","    model = UNet(in_channels=3, num_classes=2)\n","    # Total parameters and trainable parameters.\n","    total_params = sum(p.numel() for p in model.parameters())\n","    print(f\"{total_params:,} total parameters.\")\n","    total_trainable_params = sum(\n","        p.numel() for p in model.parameters() if p.requires_grad)\n","    print(f\"{total_trainable_params:,} training parameters.\")\n","    outputs = model(input_image)\n","    print(outputs.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9N-Kn8OOmuV3","executionInfo":{"status":"ok","timestamp":1715119616739,"user_tz":420,"elapsed":10307,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}},"outputId":"74588961-dc00-4bd7-cfcd-bf28af5058da"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["31,037,698 total parameters.\n","31,037,698 training parameters.\n","torch.Size([1, 2, 512, 512])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jhBKk8DPnluP"},"execution_count":null,"outputs":[]}]}