{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMpR1WUoayo9IZYME4W2OWZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LjCteTqX4WNS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708017654756,"user_tz":480,"elapsed":19527,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}},"outputId":"cad66dd1-c028-4131-c815-7e659bc8eb5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"]},{"cell_type":"code","source":["import os\n","from os import listdir\n","from os.path import isfile, join\n","import nibabel as nib\n","import imageio\n","import numpy as np\n","import torch\n","from torchvision.utils import save_image\n","import torchvision.transforms.v2.functional as TF\n","from torchvision.transforms import v2\n","\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","import nibabel as nib"],"metadata":{"id":"F8Gh3d3td4C2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(13)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWvs6hmXd6Wl","executionInfo":{"status":"ok","timestamp":1708017666685,"user_tz":480,"elapsed":174,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"}},"outputId":"91a31e37-3075-470e-ad53-e754b98274b5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["data_dir = (\"U-Net/data/NIFTIs_03/040102N\")"],"metadata":{"id":"HbmsXQZ-zHxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_files = [f for f in sorted(listdir(data_dir)) if isfile(join(data_dir, f))]\n","\n","# call train/test split based on len(data_files)\n","train_files = data_files[:4]\n","test_files = data_files[4:]"],"metadata":{"id":"ozNA9dDE_A66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_files"],"metadata":{"id":"Llk1OmCu_Em2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lq-vNBYLRgmq"},"source":["Check both training files have same length"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12219,"status":"ok","timestamp":1714521305361,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"},"user_tz":420},"id":"ZkexkHv3RgOo","outputId":"f0f7c638-ac08-4e49-edda-b8f96bcfcda4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Image file 0 has 352 number of images\n","Image file 1 has 352 number of images\n"]}],"source":["for idx in range(0, len(train_files), 2):\n","  train_img = nib.load(join(data_dir, data_files[idx])).get_fdata()\n","  train_mask = nib.load(join(data_dir, data_files[idx+1])).get_fdata()\n","\n","  print(f\"Image file {idx//2} has {train_img.shape[0]} number of images\")"]},{"cell_type":"markdown","metadata":{"id":"B31Ik_--glE7"},"source":["Helper function to name saved image files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LqZRjnL0goSx"},"outputs":[],"source":["def pad_int(run_id, zfill=4):\n","  # pad id number to 4 digits\n","  return str(run_id).zfill(zfill)\n","\n","def get_fname(fnumber, img_bool):\n","  fnum = pad_int(fnumber)\n","  return f\"{fnum}_img.png\" if img_bool else f\"{fnum}_msk.png\""]},{"cell_type":"markdown","metadata":{"id":"l5oC_LHYL2dd"},"source":["Automate reading in of .img and .msk for U-Net training.\n","\n",".msk files had multiple colors around segmentation instance confusing the neural network. To improve training data quality we ensure monochromatic segmentations. Only two colors should be present in masking images: one for the background and one for the segmented instance"]},{"cell_type":"markdown","source":["Train file 1: 168-225 (green/yellow)\n","\n","Train file 2: 452-497, 526-574 (green/yellow)\n","(offset by 352)\n","\n","Test file: 98-142, 172-227 (green/yellow)"],"metadata":{"id":"zs_59Ov0ZAcs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgCVx7ZGMmYf"},"outputs":[],"source":["save_img_dir = \"U-Net/data/train_monochromatic/\"\n","\n","# iterate over train_data\n","t_file_id = 0\n","for idx in range(0, len(train_files), 2):\n","  train_img = nib.load(join(data_dir, data_files[idx])).get_fdata()\n","  train_mask = nib.load(join(data_dir, data_files[idx+1])).get_fdata()\n","\n","  # loop over first dimension of image, every timeslice will be a training image\n","  for timeslice in range(train_img.shape[0]):\n","    # assign img/mask to corresponding slice\n","    train_slice = train_img[timeslice, :, :]\n","    mask_slice = train_mask[timeslice, :, :]\n","    # assign segmentation area pixels in mask to monochromatic pixel value (in this instance to 12.0)\n","    mask_slice = np.where(mask_slice != 0.0, 1938.0, 0.0) # 1938.0\n","\n","    # create appropriate image/mask filename\n","    img_fname = get_fname(t_file_id*train_img.shape[0]+timeslice, img_bool=True)\n","    mask_fname = get_fname(t_file_id*train_img.shape[0]+timeslice, img_bool=False)\n","\n","    # save image/mask\n","    plt.imsave(join(save_img_dir, img_fname), train_slice)\n","    plt.imsave(join(save_img_dir, mask_fname), mask_slice)\n","\n","  t_file_id += 1"]},{"cell_type":"markdown","metadata":{"id":"EqtcVhpUjt-7"},"source":["Repeat above process for the testing set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iS9R1tZ0j7xy"},"outputs":[],"source":["save_img_dir = \"U-Net/data/test_monochromatic/\"\n","\n","test_img = nib.load(join(data_dir, \"040102_19010811_Sag_CUBE_T1_FS_img.nii\")).get_fdata()\n","test_mask = nib.load(join(data_dir, \"040102_19010811_Sag_CUBE_T1_FS_msk.nii\")).get_fdata()\n","\n","for timeslice in range(test_img.shape[0]):\n","  test_slice = test_img[timeslice, :, :]\n","  mask_slice = test_mask[timeslice, :, :]\n","  mask_slice = np.where(mask_slice != 0.0, 1938.0, 0.0) # 1938.0\n","\n","  img_fname = get_fname(timeslice, img_bool=True)\n","  mask_fname = get_fname(timeslice, img_bool=False)\n","  plt.imsave(join(save_img_dir, img_fname), test_slice)\n","  plt.imsave(join(save_img_dir, mask_fname), mask_slice)\n"]},{"cell_type":"markdown","source":["Check length of each data folder to ensure all images were correctly saved"],"metadata":{"id":"8fspHgopynLP"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":243,"status":"ok","timestamp":1714493717209,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"},"user_tz":420},"id":"E4fNTjtTCMyA","outputId":"940e3573-5490-421b-cfcc-356410deb9e1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1408"]},"metadata":{},"execution_count":174}],"source":["len(listdir(\"U-Net/data/train\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247,"status":"ok","timestamp":1714493973586,"user":{"displayName":"Erik Johansson","userId":"01074076572453530700"},"user_tz":420},"id":"0xs019yVCduv","outputId":"10a9fbf9-bd67-47f5-8cdd-261bb24c7d52"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["672"]},"metadata":{},"execution_count":178}],"source":["len(listdir(\"U-Net/data/test_monochromatic\"))"]}]}
