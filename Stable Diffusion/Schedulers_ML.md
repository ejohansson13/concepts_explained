# Schedulers

This page is intended to cover schedulers and the more popular scheduling algorithms utilized with Stable Diffusion models. These schedulers are  mathematical equations for the reverse diffusion process and adapted to neural network architectures for the purpose of image generation. This is intended to be a summary overview, and will focus on broad comparisons between the research papers inspiring these algorithms. There are many more schedulers than those covered here. This page will abstract rigorous mathematical concepts and attempt to summarize each paper's contribution to the advancement of diffusion models.

All quotes, ideas, and images from the summarization of each research paper are taken from the accompanying paper unless cited otherwise.

## Background

Forward process: addition of noise.
Reverse process: intractable reverse process of denoising variables, entire dataset is necessary to calculate it.
Generative process: approximation of reverse process.

## DDPM

The first of a generation of research papers re-examining diffusion models for image synthesis, [Denoising Diffusion Probabilistic Models (DDPM)](https://arxiv.org/abs/2006.11239) proposed that diffusion models were capable of synthesizing high-quality images and bridged [noise conditional score networks](https://arxiv.org/pdf/1907.05600) during training with annealed Langevin dynamics while sampling. Following the [2015 Sohl-Dickstein et. al paper](https://arxiv.org/pdf/1503.03585), diffusion models were Markov chains parameterized with Gaussian noise and trained to reverse the diffusion process to generate samples matching their training data. Sohl-Dickstein proved that, given small additions of Gaussian noise along the Markov chain, both the forward and reverse processes would express valid samples from the same underlying distribution.

The forward process of adding noise to an image was dependent on a predetermined, linear schedule of variances. Adhering to Markov chain principles, each state was solely dependent on the previous state. A benefit of expressing the forward process as a schedule of variances was its sampling ability of any arbitrary latent variable along the chain. Reparameterizing the forward variance and taking the cumulative product of the rewritten variance allowed succinct expression of any state of x dependent only on the initial state. This removed the sequential restrictions of a Markov chain in the forward process. This equation can be seen below. Here, $\alpha$<sub>t</sub> is 1 - $\beta$<sub>t</sub> where $\beta$<sub>t</sub> is the forward process variance at time t. $\overline{\alpha}$<sub>t</sub> refers to the cumulative product of all $\alpha$<sub>t</sub> until time t. Researchers rescaled the signal with each forward step by  $\sqrt{{\alpha}_t}$ to prevent growing variance with each noising step. The signal rescaling also provided constantly scaled inputs to the neural network.

<p align="center" width="100%">
  <img src="/Stable Diffusion/Images/Schedulers_Images/nice_property.png" width="50%">
</p>

The negative log likelihood of the reverse process (removing noise to arrive at a clean signal) could be optimized to arrive at an objective function comparing Gaussians via KL divergence. This simplified objective function was then optimizable via MSE and easily compatible with neural network architectures. The rewritten likelihood can be seen below.

<p align="center" width="100%">
  <img src="/Stable Diffusion/Images/Schedulers_Images/ddpm_nll_optimized.png" alt="Optimized negative log likehood equation for DDPM" width="100%">
</p>

The forward process variances could either be learned through reparameterization or treated as hyperparameters. The authors elected to treat them as hyperparameters, fixing them to constant values, and allowing the  L<sub>T</sub> term to be treated as a constant. Determining the  L<sub>t-1</sub> term defined the relationship between the forward noising process and the reverse generative process. Resolving the reverse generative process then became dependent on learning its mean and variance. The authors opted to tie the reverse process variance to the forward process variance. This could be implemented by rewriting the reverse process variance as a standard deviation constant multiplied by the identity matrix, where the standard deviation at every timestep was the square root of the forward process variance. This was also optimal for x<sub>0</sub> sampled from normal distribution with 0 mean and identity variance.

After determining that the L<sub>t-1</sub> term depended on the mean and variance of the denoising process, and accounting for the variance, the authors rewrote the L<sub>t-1</sub> term[Eq. 8]. The rewritten loss served to minimize the distance between the reverse process mean approximator and the forward process posterior mean. This could then be reparameterized such that the reverse process mean function approximator was solely responsible for predicting the added noise to the original image[Eq. 12]. The authors noted that the approximator could also predict the original image, but in their research, this led to lower-quality results. The parameterization of the function approximator to predicting added noise bore similarities to both Langevin dynamics and [denoising score-matching](https://arxiv.org/pdf/1907.05600).

The L<sub>0</sub> term could then be modeled using a separate, discrete decoder, although the authors left open the possibility that a more powerful, autoregressive decoder could also be employed. Having defined the reverse process and its final step decoder, the authors tweaked the final loss term, removing the weighting coefficient [Eq. 14], finding it improved sample quality and was easier to implement for model training. Additionally, the weighting coefficient from Eq. 12 down-weighted early steps in the Markov Chain, which was effectively implemented in the linear schedule of the forward process variance.

Supplementary conclusions from the paper determined that minimizing the early steps of the denoising process led to increased sample quality, likely as a result of allowing the model to focus on the more difficult denoising tasks. Researchers selected a U-Net architecture to model their training objective and observed its success at inference time despite non-competitive lossless codelengths, affirming the U-Net’s superior performance with spatial data. Other experimental details were maintained in later literature: temporal information was embedded into the U-Net, parameters were shared across timesteps, and each forward step in the noising process scaled down the signal input to prevent exploding variances across the chain. Similar to [previous](https://arxiv.org/pdf/1503.03585) [literature](https://arxiv.org/pdf/1907.05600), 1000 steps at inference time were taken to gauge sample quality. This also served as a baseline for future diffusion research. Researchers examined the rate-distortion tradeoff of devoting bits to model images and found that a majority of bits were devoted to modeling imperceptible image details. This conclusion was a consistent issue in pixel-space diffusion and was the underlying theory behind [Latent Diffusion Models](https://arxiv.org/pdf/2112.10752) and their decision to first encode images to a latent space prior to learning their conceptual composition. The original graph can be seen below.

<p align="center" width="100%">
  <img src="/Stable Diffusion/Images/Schedulers_Images/DDPM_graph.png" width="45%" /> 
</p>

DDPMs were the first step taken to revisit diffusion theory for image generation and, contemporarily, performed competitively in many image quality metrics. They were reliant on an unconditional model architecture with a wholly stochastic generative process due to the introduction of an additional noise component in the generative process. Image generation and training was also prohibitively expensive due to pixel-space interpolations, with training on the CIFAR-10 dataset requiring the equivalent of 84.8 hours on a V100 GPU. DDPMs served as an important step forward in the utilization of diffusion theory for deep generative models, where diffusion quickly demonstrated impressive capacity in a variety of applications. 

### Conclusion

DDPMs revisited the diffusion theory of Sohl-Dickstein et. al’s 2015 research paper and conceptually linked denoising diffusion to contemporary research literature, including noise-conditional score networks. Treating the noising and subsequent denoising of images as latents along a Markov chain, researchers were able to train a neural network to estimate and remove arbitrary quantities of noise from an image. Sampling from randomly sampled noise created coherent images from scratch. Researchers determined that training and sampling in the pixel-space was computationally expensive and the majority of digital bits devoted to an image contained imperceptible, high-frequency details.

## iDDPM

Following the success of the [DDPM paper](https://arxiv.org/pdf/2006.11239), researchers attempted to improve on DDPM’s primary weaknesses through a variety of approaches. One approach, [Improved Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2102.09672), or iDDPMs, focused on the underperforming log-likelihood of the DDPM compared to other generative models. [Generative Adversarial Networks](https://arxiv.org/pdf/1406.2661) had demonstrated satisfactory performance at a variety of image generation metrics, but struggled to capture broad data distributions. [Razavi et. al in 2019](https://arxiv.org/pdf/1906.00446) argued that optimizing the log-likelihood for generative models pushed those models to capture all of the modes of the data distribution. iDDPM focused on improving the performance of diffusion models in log-likelihood along with other proposed improvements to the sampling processes. 

The authors began by retracing the derivation that led to the initial DDPM loss function. [Ho et. al](https://arxiv.org/pdf/2006.11239) reweighted the variational-lower bound loss to achieve their L<sub>simple</sub> function. Ho et. al argued that the simplified loss function generated better sample quality than training on L<sub>VLB</sub> directly and tied the empirical results to an intuitive resemblance to relevant 2019 literature by [Song and Ermon](https://arxiv.org/pdf/1907.05600). The DDPM L<sub>simple</sub> function had no input for the generative variance as they concluded image quality was far more dependent on the mean of the generative process. The authors of iDDPM agreed, but argued that similar image quality could be achieved with improved log-likelihood if a better method for determining the generative process variance was discovered. The revised generative variance would have to be achieved while avoiding the training instability and inferior sample quality encountered in the original DDPM paper. The iDDPM authors elected to reparameterize the generative variance as an interpolation between the timestep-dependent noise variance and the cumulative product of the forward noising variances. The equation is given below.

<p align="center" width="100%">
  <img src="/Stable Diffusion/Images/Schedulers_Images/iddpm_generative_variance.png" width="60%">
</p>

The interpolation was dependent on an introduced log-linear vector v, containing one element per dimension. The newly reparameterized generative variance was ineffective without the model learning its optimization. This required a new loss function denoted as the L<sub>VLB</sub> term. L<sub>VLB</sub> was solely responsible for guiding the generative process variance and was set a small coefficient (0.001) to prevent it from overwhelming the L<sub>simple</sub> term. The linear combination of the L<sub>simple</sub> and L<sub>VLB</sub> terms was designated L<sub>HYBRID</sub>.

Initially, authors expected optimizing L<sub>VLB</sub> directly would result in the optimal log-likelihood. Instead, the noisy gradients of L<sub>VLB</sub> were detrimental to the training process. Mitigating the noisy gradients, the authors employed importance sampling which significantly smoothed out the direct optimization of L<sub>VLB</sub> but was unhelpful in optimizing L<sub>HYBRID</sub>.

Another improvement the authors proposed was altering the noise schedule. The linear noise schedule from the original DDPM paper demonstrated sufficient functionality with high-resolution images, but struggled with lower resolution images. The authors determined the end of the linear schedule was too noisy with the model learning little from a borderline isotropic distribution. Instead the authors constructed a cosine schedule, clipping the maximum value to 0.999 and adding an offset of 0.008 to prevent abrupt changes in the noise level at the start or end of the process. The primary motivation for the new schedule was combating the acceleration of additive noise at the end of the noising schedule. Employing a cosine schedule mitigated this issue while maintaining a near linear drop-off in the middle of the noising schedule. The cosine noise schedule resolved the marked fluctuations in noise level at the start and end of the noising process, but was ultimately an arbitrary decision. The authors noted that other mathematical functions with offsets at the start and end of the process would likely perform similarly.

After implementing the above changes to the DDPM methodology, the authors measured their efforts. Training on  L<sub>HYBRID</sub> with a cosine noise schedule provided similar FID performance with improved log-likelihood performance. Extended optimization on the L<sub>VLB</sub> term resulted in further log-likelihood improvement but was detrimental to the FID performance. 

Next, the authors examined another flaw in the original DDPM paper: slow, sequential, sampling speed. Unable to combat the sequential nature of sampling, they analyzed other methods to accelerate the process. After training the model for many more steps than the original DDPM paper (4000 vs 1000) in an effort to improve the sampling quality, the authors noted that they were able to successfully generate high-quality images in as few as 50 steps. Reducing 4000 steps to 50 steps was implemented by using 50 evenly spaced steps along the chain from 1 to 4000. Sampling via this accelerated fashion comprehensively outperformed the DDPM sampled with the same number of steps. 

The authors also examined distribution coverage of diffusion models compared to GANs, how model performance would scale with compute, and the potential benefits of a stronger conditioning signal on diffusion similar to [Chen et. al in 2020](https://arxiv.org/pdf/2009.00713). All of these topics were also covered in a [later paper by the same authors](https://arxiv.org/pdf/2105.05233) a few months later. 

### Conclusion

iDDPMs attempted to improve on DDPMs and combat their ostensible weaknesses. iDDPMs learned the reverse diffusion generative variance through reparameterization in an attempt to improve the log-likelihood performance of DDPMs. They found that optimizing directly on the loss term responsible for improving the log-likelihood was detrimental to model performance but, optimizing on a hybrid loss term led to superior performance over the original DDPM. The authors also introduced a cosine noising schedule, combating the isotropic properties found approaching the end of a linear noising schedule. The cosine noising schedule empirically improved model performance, but the authors noted that other mathematical functions with similar properties would perform equally. Lastly, the authors experimented with an accelerated sampling schedule to mitigate the slow, sequential sampling process of DDPMs and found that sampling from a subset of equally spaced timesteps required fewer model evaluations with negligible impact on model performance.

## DDIM

[Denoising Diffusion Implicit Models (DDIMs)](https://arxiv.org/abs/2010.02502) were directly inspired by [Denoising Diffusion Probabilistic Models(DDPMs)](https://arxiv.org/pdf/2006.11239). While [Improved Denoising Diffusion Probabilistic Models (iDDPMs)](https://arxiv.org/pdf/2102.09672) improved the log-likelihood of diffusion models (among other contributions), the primary contribution of DDIMs was improving the sampling speed of diffusion models without sacrificing sample quality. 

The key purpose of diffusion models is constructing a generative process to approximate the denoising of noised images. Denoising is a reversal of the forward noising process, leading to an inherent relationship between the generative process and the forward noising process. To improve the speed of the generative process, the authors examined changes to the iterative forward noising of images. They observed that the DDPM learning objective was solely dependent on the marginal distribution of the initial, clean image and its final, noisy latent. The objective was not dependent on the joint probability distribution of the sequential latents necessary to transition from one destination to the other. Researchers noted that many joint distributions exist with equivalent marginal distributions, expanding possible noising processes beyond Markovian ones, while maintaining the DDPM learning objective.

Researchers indexed the new family of noising distributions by a vector 𝝈, with 𝝈 controlling the stochasticity of the noising process. They proved that, for a certain 𝝈, the forward noising process became Markovian and the corresponding generative process would be a DDPM. Any other value of 𝝈 would create a non-Markovian forward noising process, with latent states depending on both their previous state and the original state. Reversing the noising process allowed for a defined denoising process dependent on the vector 𝝈. Any latent variable x<sub>t-1</sub> would be dependent on both the initial variable x<sub>0</sub> and x<sub>t</sub>. This would create the framework for training the generative process. The generative training process added noise to an initial clean image x<sub>0</sub>, achieving x<sub>t</sub>. The model would estimate the added noise and remove it from x<sub>t</sub> to achieve a predicted x<sub>0</sub>. Given the two dependencies x<sub>0</sub> and x<sub>t</sub>, the model could employ the defined denoising distribution to predict the denoised state x<sub>t-1</sub>. This iterative process was necessary for inference, where the model would only be given a noisy latent and need to progressively denoise it to arrive at a clean and coherent image.

Alternatively, assigning 𝝈 to zero, the authors arrived at an entirely deterministic process. With 𝝈 determining the stochasticity of the noising process, setting 𝝈 to zero achieved deterministic control. Describing the generative instance as a Denoising Diffusion Implicit Model, the authors related their discovery to [Mohamed and Lakshminarayanan’s](https://arxiv.org/pdf/1610.03483) definition of an implicit probabilistic model. Rather than approximating the data distribution with a likelihood function, implicit probabilistic models generate samples from the underlying data distribution through a defined stochastic process. The generated images of DDIMs are inextricably tied to their initial latent variable. This property also guarantees that for an observed x<sub>0</sub> and x<sub>t</sub> (where x<sub>t</sub> is easily achievable, given x<sub>0</sub>), x<sub>t-1</sub> becomes known and fixed, exemplifying the consistency of the DDIM sampling process.

The deterministic property of DDIMs guarantees that the same initial latent will always map to the same destination image, given the same number of parameters and steps taken. This was not possible with DDPMs, due to the stochasticity in the forward noising process and reverse denoising process. Varying the number of steps for a DDIM will result in images sharing a large number of high-level features, e.g. yellow-and-black birds with differing patterns or beak shapes. The consistency of DDIMs allowed for latent encodings along the generative process, applicable for a variety of downstream tasks. The authors examined latent variable interpolation to alter the high-level features of images and drive them towards semantically meaningful combinations of specific concepts.

Model training for any generative process could be optimized via the variational objective J<sub>𝝈</sub>. Seemingly, the variational objective required retraining different models for any and all 𝝈. However, the authors proved a linear relationship between J<sub>𝝈</sub> and the DDPM objective. This allowed a model trained with the DDPM objective to be functionally compatible with the 𝝈-dependent generalization of the new family of generative processes and vice versa. Similar to iDDPM, the authors recognized that this algorithmic compatibility with differing training structures allowed for a model to be trained with a greater number of forward steps (in the hopes of better understanding image compositions), while only sampling from a subset of them. The authors suggested this theory, but left empirical examinations to future work. The cross-algorithmic compatibility of these processes allowed for models to be trained once with the DDPM variational objective in the forward process and utilize any other 𝝈-dependent generative process for sampling. This was one of the first steps towards incorporating different sampling algorithms for the same model architecture, a critical concept for [Latent Diffusion Models](https://arxiv.org/pdf/2112.10752).

Training with an arbitrary number of forward steps, while only sampling from a subset, also allowed for accelerated sampling schedules. Since the denoising objective was not dependent on any specific forward noising process, noising processes with compressed schedules could be considered, allowing the utilization of their shorter generative processes. This allowed for far fewer timesteps needed at sampling time compared to those taken in training. Researchers considered shortening schedules in both linear and quadratic fashions, with both methods demonstrating capable performance with different datasets. The authors demonstrated that DDIMs emphatically outperformed DDPMs with shortened sampling schedules, achieving comparable image quality 10x or 50x faster than DDPMs. For three of the four datasets researchers examined, DDIMs outperformed DDPMs given 10, 20, 50, and 100 iterations. In the final dataset, DDIMs outperformed DDPMs at 10, 20, and 50 steps, with worse performance at 100 steps.

Researchers’ theoretical derivation of the variational objective lifted diffusion sampling from the restrictions of Langevin dynamics. Langevin dynamics translate a continuous gradient flow to a discrete procedure, but require many iterations to achieve a high-quality approximation. This theoretical stipulation intrinsically limits the ability of DDPMs to generate high-quality images in fewer iterations. In contrast, DDIMs coherently and deterministically map isotropic noise back to the original image. This mapping and its accompanying consistency property allow for an accelerated sampling schedule to accomplish the majority of the high-level features of the image in far fewer iterations, ceding a legitimate tradeoff between sampling speed and image quality.

After achieving a formula for predicting the iteratively denoised latent state, the authors rewrote the equation, and reparameterized key variables to express an equation similar to the Euler solver of an Ordinary Differential Equation (ODE). The authors noted the similarities between their reparameterization and [Song et. al’s 2020 paper](https://arxiv.org/pdf/2011.13456) examining probability flow ODEs. Despite the equivalency of the ODEs, their respective sampling procedures differed, with the differences emphasized when fewer sampling steps were taken. However, the authors’ perspective shift in examining diffusion as an ODE problem set the stage for [future literature](https://arxiv.org/pdf/2206.00364).

### Conclusion

DDIMs defined a new family of generative diffusion models, indexed by a vector 𝝈. Revisiting the theoretical derivation of DDPMs, they observed the corresponding learning objective was solely dependent on the marginal distribution of the original image and its noisy counterpart. Rewriting the variational objective, they observed compatibility across all members of the new family. This allowed plug-and-play functionality, where an architecture trained for one instance of 𝝈 could be sampled with any other value of 𝝈. Setting 𝝈 to 0 created a deterministic mapping of noisy latents to their clean, denoised signal. The authors additionally explored accelerated sampling schedules. They found that the compatibility of the variational objective across 𝝈 values allowed for a longer noising schedule to be used in training, while a compressed noise schedule was employed for sampling. They explored different implementations and found that, with the accelerated sampling schedules, DDIMs comprehensively outperformed DDPMs at fewer sampling steps. After releasing DDIMs from the theoretical restrictions of Langevin dynamics, the authors reparameterized the DDIM iterate to resemble the first-order Euler solver of Ordinary Differential Equations, a useful perspective for future literature.

## EDM

[Elucidating the Design Space of Diffusion-Based Generative Models (EDM)](https://arxiv.org/pdf/2206.00364) was released after the initial [Latent Diffusion Models paper](https://arxiv.org/pdf/2112.10752) and seeked to simplify the design space for diffusion models. The authors argued the existing theory for diffusion models was “unnecessarily convoluted” and, in an effort to protect the theory behind these models, previous researchers had created a complex, inseparable framework for constructing diffusion-based models. Inspired by the overlapping field of [score-based denoising models](https://arxiv.org/pdf/2011.13456), the authors shifted the traditional perspective of diffusion theory to a differential equation perspective. Researchers examined diffusion as the approximation of a probability flow trajectory between random noise and coherent images. Additionally, the authors elucidated design choices for diffusion-based models, demonstrated the separability of these choices from each other and the model architecture, and suggested improvements for model training and inference performance.

Following [Song et. al](https://arxiv.org/pdf/2011.13456), the authors examined diffusion as a probability flow Ordinary Differential Equation (ODE), with continuous noise levels dependent on time and varying with the forward or reverse progression of an image. Similar to previous literature, they allowed a schedule defining the noise level of a latent at time t. The evolution of a sample between two points in time could then be described as the gradient of the data distribution, considered the score function. The forward progression of a latent would augment the quantity of noise, stepping backwards would reduce the quantity of noise. The trajectories taken by latents could then be visualized in a simplified graph of the ODE curvature, as presented in a [video lecture](https://www.youtube.com/watch?v=T0Qxzf0eaio) by one of the paper’s authors.

Considering diffusion as an ODE problem, the authors abstracted away the derivations and theoretical background of previous diffusion literature to examine the tangible choices responsible for determining a functioning scheduling procedure. Insulated from the rigor of their theoretical derivations, the authors examined these design choices empirically to determine the optimal choices moving forward. Table 1, shown below, depicted the possible design choices of sampling algorithms and the values of those choices for previous diffusion literature.

<p align="center" width="100%">
  <img src="/Stable Diffusion/Images/Schedulers_Images/table1_karras.png" width="100%">
</p>

Given the continuous probability flow between an initial random noise latent and its coherent image destination, the authors focused on best approximating the probability flow trajectory. Due to the iterative nature of noising and denoising an image, discretized progress along the continuous trajectory would always introduce some truncation error. Larger steps along the solution trajectory would arrive at a solution faster, but introduce more truncation error in the process. Smaller steps would best approximate the solution trajectory, but at a prohibitive cost. The best solution would successfully navigate the tradeoff between speed and approximation error.

Along the trajectory between coherent images and random noise, the shape of the probability flow fluctuated the least towards the end of its noising trajectory. With a large quantity of random noise added to the image, adding further random noise would not have a significant effect on the data distribution. Opposingly, with a minimum amount of noise added to the image, further additive noise had a significant effect on the curvature of the probability flow. The authors found that the end of the noising trajectory was largely linear, allowing larger steps to be taken with minimal risk of introducing error. To achieve the dual objective of large steps at the start and smaller, more precise steps near the end of the denoising trajectory, the authors arrived at a polynomial parameterization of the time steps. The polynomial exponent determined the compromise between larger steps at the start and smaller steps at the end of solution trajectory, and was determined empirically.

Having determined the optimal approximation of the denoising solution trajectory, the authors examined two factors responsible for affecting the shape of the trajectory itself. Signal scaling was introduced in the 2021 Song et. al paper as a method of combating the large signal magnitudes representing noise levels as images are progressively noised. The noising schedule determined the proportional relationship between magnitude of added noise and time t. Both of these functions offered approaches to altering the solution trajectory. The initial less noisy portions of the trajectory could be “stretched out”, allowing the discrete approximation to spend more time near the end of the solution trajectory. Examining the effects of both of these functions on the probability flow curvature, the authors determined the [DDIM](https://arxiv.org/pdf/2010.02502.pdf) choices simplified the ODE and performed best empirically. Another avenue for improved performance examined by researchers was the introduction of higher-order solvers. Most literature on diffusion had defaulted to using the first-order Euler solver, as expressed in the DDIM paper. The authors examined using Heun’s 2nd-order method, which included an additional denoising evaluation at every step, to correct the solution trajectory in the hopes of better approximating the probability flow. Empirically, the authors found the higher-order solver to offer improved performance.

Performing a comprehensive overview of their recommended improvements to sampling schedules, and previous literature, the authors input their scaling, noise scheduling, and timestep schedules into previous diffusion models. They found empirical improvement over the previous models on every dataset they examined, as measured by FID. Additionally, they found that utilizing their suggested improvements on previously trained models required fewer steps to generate high-quality images.

Another avenue examined by researchers was the role of stochasticity in diffusion. The solution trajectories examined by the authors were primarily based on ODEs. Song et. al’s paper was concentrated on Stochastic Differential Equations (SDEs), and the initial resurfacing of diffusion models, [DDPMs](https://arxiv.org/pdf/2006.11239) also utilized a stochastic process. Expressing the SDE from Song et. al as an ODE with a Langevin diffusion SDE component, the authors argued that incorporating stochasticity during sampling led to improved solving performance. Their argument was that the ODE component following the solution trajectory was complemented by the SDE component serving as a corrector for the truncation error. The Langevin diffusion SDE component could be further understood as a deterministic noise decay supplemented with noise injection at every denoising step. Ultimately, the researchers determined that the optimal amount of stochasticity for each application should be determined empirically, but argued that some amount of stochasticity in the middle of the solution trajectory was beneficial, particularly for diverse training sets. Stochasticity near the denoised result could lead the final product wayward, and away from the preferred destination.

Lastly, the authors examined other training details of diffusion models. Since the establishment of DDPMs, diffusion literature trained denoising architectures to predict the additive noise of a latent. The authors of the EDM paper agreed that the established procedure was fantastic for low and medium noise levels. At prohibitively high noise levels, the architecture was responsible for removing one large magnitude of noise from the other in the hopes of recovering a coherent signal. As a solution, the authors presented a skip connection. Within the denoising architecture, given a large magnitude of additive noise, the architecture could instead circumvent the iterative denoising process to estimate the clean image. The intuitive benefits of this procedure were not expressed empirically, but researchers argued it improved the robustness of models. 

Determining the magnitude of noise to add to training images was another focus of researchers. They posited that very low noise levels were negligible and difficult to detect in training, while even with the skip connection augmentation, the architecture learned little when applying large levels of noise. This was supported when they examined a graph illustrating the training loss against noise levels. The model learned the most at medium noise levels, approximating an upside down bell-curve. Therefore, the authors determined to institute a log-normal distribution from which to sample the additive noise magnitudes during training.

### Conclusion

EDM argued that, in an attempt to preserve solid theoretical footing, diffusion literature had unnecessarily restricted the freedom of design choices for diffusion-based image synthesis. The authors separated previous diffusion literature into a tabular design space and argued for the efficacy of certain choices. They supported their arguments by implementing the optimal design choices in previous diffusion frameworks and observing improved empirical performance. Additionally, the authors interpreted traditional diffusion literature through a probability flow perspective and examined how their presented design choices impacted probability flow navigation. Higher-order solvers combated the truncation error of iteratively discretizing the solution trajectory, a polynomial parameterization of the time steps allowed for large steps early in the denoising process and smaller steps closer to the image destination, and the DDIM choices for scaling and noise schedules were found to be optimal. Additionally, researchers determined an improved distribution to sample noise levels for training and argued for an architectural design change to improve learning at high noise levels.

# Conclusion

If you do want a look at some of the derivations and an intuitive understanding of both schedulers and the advancement of diffusion models overall, I urge you to check out [Lillian Weng's blog on diffusion models](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/) which is an invaluable resource summarizing the relevant literature.

## Citations

[1] https://www.youtube.com/watch?v=IVcl0bW3C70&t=903s

[2] https://huggingface.co/docs/diffusers/v0.14.0/en/api/schedulers/euler

[3] Helpful with DDIMs - https://www.cs.cmu.edu/~epxing/Class/10708-17/notes-17/10708-scribe-lecture19.pdf
